{
 "metadata": {
  "name": "lr-class-sgd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math \n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import optimize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('ex2data1.txt', header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data[[0,1]].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = data[2].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def random_minibatch(X, y):\n",
      "    m = X.shape[0]\n",
      "    batch_size = 0.1\n",
      "    batch_size = int(math.floor(m * batch_size))\n",
      "    while True:\n",
      "        indices = np.random.choice(np.arange(m), batch_size, replace=False)\n",
      "        yield X[indices], y[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gen = random_minibatch(X, y)\n",
      "gen.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(array([[ 62.27101367,  69.95445795],\n",
        "       [ 75.02474557,  46.55401354],\n",
        "       [ 79.94481794,  74.16311935],\n",
        "       [ 56.2538175 ,  39.26147251],\n",
        "       [ 74.49269242,  84.84513685],\n",
        "       [ 67.94685548,  46.67857411],\n",
        "       [ 34.21206098,  44.2095286 ],\n",
        "       [ 99.27252693,  60.999031  ],\n",
        "       [ 72.34649423,  96.22759297],\n",
        "       [ 77.92409145,  68.97235999]]),\n",
        " array([1, 1, 1, 0, 1, 0, 0, 1, 1, 1]))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minibatch(X, y):\n",
      "    m = X.shape[0]\n",
      "    batch_size = 0.01\n",
      "    batch_size = int(math.floor(m * batch_size))\n",
      "    max_batchs = m / batch_size\n",
      "    while True:\n",
      "        for i in range(max_batchs):\n",
      "            indices =  np.arange(i*batch_size, (i+1)*batch_size)\n",
      "            yield X[indices], y[indices]\n",
      "gen = minibatch(X, y)\n",
      "gen.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(array([[ 34.62365962,  78.02469282]]), array([0]))"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X1, y1 = X[:10], y[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X1, y1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(array([[ 34.62365962,  78.02469282],\n",
        "       [ 30.28671077,  43.89499752],\n",
        "       [ 35.84740877,  72.90219803],\n",
        "       [ 60.18259939,  86.3085521 ],\n",
        "       [ 79.03273605,  75.34437644],\n",
        "       [ 45.08327748,  56.31637178],\n",
        "       [ 61.10666454,  96.51142588],\n",
        "       [ 75.02474557,  46.55401354],\n",
        "       [ 76.0987867 ,  87.42056972],\n",
        "       [ 84.43281996,  43.53339331]]),\n",
        " array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1]))"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(object):\n",
      "    \n",
      "    def __init__(self, reg_lambda=0, opti_method='TNC'):\n",
      "        self.reg_lambda = reg_lambda\n",
      "        self.method = opti_method\n",
      "    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def hypothesis(self, X, theta):\n",
      "        return self.sigmoid(np.dot(X, theta))\n",
      "    \n",
      "    def function(self, theta, X, y):\n",
      "        m = X.shape[0]\n",
      "        h = self.hypothesis(X, theta)\n",
      "        \n",
      "        costPos = np.dot(-y.T, np.log(h))\n",
      "        costNeg = np.dot((1 - y).T, np.log(1 - h))\n",
      "        J = (costPos - costNeg) / m\n",
      "        \n",
      "        if self.reg_lambda != 0:\n",
      "            theta_filtered = np.append([0], theta[1:])\n",
      "            J = J + (self.reg_lambda / (2*m)) * np.dot(theta_filtered.T, theta_filtered)\n",
      "        \n",
      "        return J\n",
      "    \n",
      "    def function_prime(self, theta, X, y):\n",
      "        m = X.shape[0]\n",
      "        h = self.hypothesis(X, theta)\n",
      "        grad = np.dot(X.T, h - y) / m\n",
      "        \n",
      "        if self.reg_lambda != 0:\n",
      "            theta_filtered = np.append([0], theta[1:])\n",
      "            grad = grad + np.dot(self.reg_lambda / m, theta_filtered)\n",
      "        return grad\n",
      "    \n",
      "    def minibatch(self, X, y):\n",
      "        m = X.shape[0]\n",
      "        batch_size = 0.1\n",
      "        batch_size = int(math.floor(m * batch_size))\n",
      "        max_batchs = m / batch_size\n",
      "        \n",
      "        indices = np.random.choice(np.arange(m), m, replace=False)\n",
      "        X, y = X[indices], y[indices]\n",
      "        while True:\n",
      "            for i in range(max_batchs):\n",
      "                indices =  np.arange(i*batch_size, (i+1)*batch_size)\n",
      "                yield X[indices], y[indices]\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        m, n = X.shape\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        thetas0 = np.zeros(n + 1)\n",
      "        \n",
      "        thetas = thetas0\n",
      "        alpha = 0.01\n",
      "        diff = 1\n",
      "        prevJ = 1000\n",
      "        tol = 0.000001\n",
      "        i = 0\n",
      "        for _X, _y in self.minibatch(X, y):\n",
      "            thetas = thetas - alpha * self.function_prime(thetas, _X, _y)\n",
      "            newJ = float(self.function(thetas, _X, _y))\n",
      "            if not np.isnan(newJ) and newJ != float(\"inf\"):\n",
      "                diff = np.abs(newJ - prevJ)\n",
      "                \n",
      "                prevJ = newJ\n",
      "                if diff < tol or i >= 100000:\n",
      "                    break\n",
      "            alpha = alpha * 0.9 if alpha > 0.001 else alpha\n",
      "            i += 1\n",
      "        print tol, i\n",
      "        self.thetas = thetas\n",
      "        \n",
      "    def predict_proba(self, X):\n",
      "        m, n = X.shape\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        return self.hypothesis(X, self.thetas)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return (self.predict_proba(X) >= 0.5).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(opti_method='Newton-CG')\n",
      "lr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1e-06 300000\n"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(lr.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 245,
       "text": [
        "0.91000000000000003"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}