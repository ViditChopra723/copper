{
 "metadata": {
  "name": "lr-class-gd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import optimize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('ex2data1.txt', header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = data[[0,1]].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = data[2].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(object):\n",
      "    \n",
      "    def __init__(self, reg_lambda=0, opti_method='TNC'):\n",
      "        self.reg_lambda = reg_lambda\n",
      "        self.method = opti_method\n",
      "    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def hypothesis(self, X, theta):\n",
      "        return self.sigmoid(np.dot(X, theta))\n",
      "    \n",
      "    def function(self, theta, X, y):\n",
      "        m = X.shape[0]\n",
      "        h = self.hypothesis(X, theta)\n",
      "        \n",
      "        costPos = np.dot(-y.T, np.log(h))\n",
      "        costNeg = np.dot((1 - y).T, np.log(1 - h))\n",
      "        J = (costPos - costNeg) / m\n",
      "        \n",
      "        if self.reg_lambda != 0:\n",
      "            theta_filtered = np.append([0], theta[1:])\n",
      "            J = J + (self.reg_lambda / (2*m)) * np.dot(theta_filtered.T, theta_filtered)\n",
      "        \n",
      "        return J\n",
      "    \n",
      "    def function_prime(self, theta, X, y):\n",
      "        m = X.shape[0]\n",
      "        h = self.hypothesis(X, theta)\n",
      "        grad = np.dot(X.T, h - y) / m\n",
      "        \n",
      "        if self.reg_lambda != 0:\n",
      "            theta_filtered = np.append([0], theta[1:])\n",
      "            grad = grad + np.dot(self.reg_lambda / m, theta_filtered)\n",
      "        return grad\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        m, n = X.shape\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        thetas0 = np.zeros(n + 1)\n",
      "        \n",
      "        thetas = thetas0\n",
      "        alpha = 0.5\n",
      "        diff = 1\n",
      "        prevJ = 1000\n",
      "        tol = 0.000001\n",
      "        i = 0\n",
      "        while diff > tol and i < 200000:\n",
      "            thetas = thetas - alpha * self.function_prime(thetas, X, y)\n",
      "            newJ = float(self.function(thetas, X, y))\n",
      "            if not np.isnan(newJ):\n",
      "                diff = np.abs(newJ - prevJ)\n",
      "                prevJ = newJ\n",
      "            alpha = alpha * 0.9 if alpha > 0.001 else alpha\n",
      "            i += 1\n",
      "        print tol, i   \n",
      "        self.thetas = thetas\n",
      "        \n",
      "    def predict_proba(self, X):\n",
      "        m, n = X.shape\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        return self.hypothesis(X, self.thetas)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return (self.predict_proba(X) >= 0.5).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(opti_method='Newton-CG')\n",
      "lr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1e-06 104424\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(lr.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.91000000000000003"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit lr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 35.5 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.thetas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([-1.45997214,  0.55469685,  0.11127421])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Sklearn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklr = LogisticRegression(penalty='l1', C=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(sklr.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "0.91000000000000003"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sklr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 1.02 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklr.intercept_, sklr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "(array([-11.69876001]), array([[ 0.09887385,  0.09276644]]))"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using normal equation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegressionNE(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.theta = None\n",
      "    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def hypothesis(self, X, theta):\n",
      "        return self.sigmoid(np.dot(X, theta))\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        m = X.shape[0]\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        self.theta = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), y)\n",
      "        \n",
      "    def predict_proba(self, X):\n",
      "        m, n = X.shape\n",
      "        X = np.append(np.ones(m).reshape(m,1), X, axis=1)\n",
      "        return self.hypothesis(X, self.theta)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return (self.predict_proba(X) >= 0.5).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrne = LogisticRegressionNE()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrne.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrne.theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "array([-1.29749694,  0.01484087,  0.01394217])"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(lrne.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.65000000000000002"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit lrne.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 121 us per loop\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}