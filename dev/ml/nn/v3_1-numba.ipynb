{
 "metadata": {
  "name": "v3_1-numba"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Version 3.1 includes batch, minibatch and rmsprop. Plus tested optimization algorithms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import math\n",
      "import numpy as np\n",
      "from scipy import optimize\n",
      "from scipy.io import loadmat\n",
      "import sklearn.datasets as datasets\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numbapro import vectorize, float64, jit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Init"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_network(layers):\n",
      "    return [(layers[i + 1], layers[i] + 1) for i in range(len(layers) - 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers = [25]\n",
      "layers.insert(0, X.shape[1])\n",
      "layers.insert(len(layers), np.unique(y).shape[0])\n",
      "weights_meta = build_network(layers)\n",
      "weights_meta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[(25, 401), (10, 26)]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pack_weigths(*weights):\n",
      "    tuples = tuple([theta.reshape(-1) for theta in weights])\n",
      "    return np.concatenate(tuples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths_gen(weights, weights_meta):\n",
      "    start_pos = 0\n",
      "    for layer in weights_meta:\n",
      "        end_pos = start_pos + layer[0] * (layer[1])\n",
      "        theta = weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        yield theta\n",
      "        start_pos = end_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths_gen_inv(weights, weights_meta):\n",
      "    end_pos = len(weights)\n",
      "    for layer in reversed(weights_meta):\n",
      "        start_pos = end_pos - layer[0] * (layer[1])\n",
      "        theta = weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        yield theta\n",
      "        end_pos = start_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rand_init(weights_meta, epsilon_init):\n",
      "    s = 0\n",
      "    for t in weights_meta:\n",
      "        s += t[0] * t[1]\n",
      "    return np.random.rand(s, ) * 2 * epsilon_init - epsilon_init"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1234)\n",
      "thetas0 = rand_init(weights_meta, 0.12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Sigmoid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    return np.divide(1, (1 + np.exp(-z)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@jit(float64[:](float64[:]))\n",
      "def sigmoid_numba(z):\n",
      "    return np.divide(1, (1 + np.exp(-z)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sigmoid(np.random.rand(100000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 3 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sigmoid_numba(np.random.rand(100000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 2.85 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Forward"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = loadmat('ex3data1.mat')\n",
      "X, y = data['X'], data['y']\n",
      "y = y.reshape(X.shape[0], )\n",
      "y = y - 1  # Fix notation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = loadmat('ex3weights.mat')\n",
      "theta1_sol, theta2_sol = data['Theta1'], data['Theta2']\n",
      "thetas_sol = pack_weigths(theta1_sol, theta2_sol)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def forward(weights, weights_meta, X):\n",
      "    m = X.shape[0]\n",
      "    ones = np.ones(m).reshape(m, 1)\n",
      "            \n",
      "    a_prev = np.hstack((ones, X))  # Input layer\n",
      "    for theta in unpack_weigths_gen(weights, weights_meta):\n",
      "        # Hidden Layers\n",
      "        z = np.dot(theta, a_prev.T)\n",
      "        a = sigmoid(z)\n",
      "        a_prev = np.hstack((ones, a.T))\n",
      "    return a  # Output layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit forward(thetas_sol, weights_meta, X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 17.9 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "I am waiting for a new version of Numba that fixes the bug: https://github.com/numba/numba/issues/268"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@jit(float64[:](float64[:], float64[:], float64[:, :]))\n",
      "def forward_numba(weights, weights_meta, X):\n",
      "    m = X.shape[0]\n",
      "    ones = np.ones(m).reshape(m, 1)   \n",
      "    a_prev = np.hstack((ones, X))  # Input layer\n",
      "    for theta in unpack_weigths_gen(weights, weights_meta):\n",
      "        # Hidden Layers\n",
      "        z = np.dot(theta, a_prev.T)\n",
      "        a = sigmoid(z)\n",
      "        a_prev = np.hstack((ones, a.T))\n",
      "    return a  # Output layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "Block(3)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-59-1de06f6cb483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/decorators.pyc\u001b[0m in \u001b[0;36m_jit_decorator\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'llvm_ee'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Engine should never be provided\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         sig, lfunc, wrapper = compile_function(\n\u001b[0;32m--> 222\u001b[0;31m             env, func, argtys, restype=return_type, nopython=nopython, **kwargs)\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumbawrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_numba_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/decorators.pyc\u001b[0m in \u001b[0;36mcompile_function\u001b[0;34m(env, func, argtypes, restype, **kwds)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'llvm_module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'llvm_module'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mfunc_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mfunction_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_specialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36mcompile2\u001b[0;34m(env, func, restype, argtypes, ctypes, compile_only, **kwds)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pipeline_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mfunc_ast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mpost_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mfunc_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0msymtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymtab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ast, env)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_composed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, ast, env)\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0mstage_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast2tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36m_stage\u001b[0;34m(ast, env)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mstage_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_stages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_check_stage_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m             \u001b[0m_stage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ast, env)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumbaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mfunc_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/pipeline.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, ast, env)\u001b[0m\n\u001b[1;32m    497\u001b[0m             **func_env.kwargs)\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mfunc_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mfunc_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/codegen/translate.pyc\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_phis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate_cleanup_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/codegen/translate.pyc\u001b[0m in \u001b[0;36mhandle_phis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;31m# Add all incoming values to all our phi values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mssa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_phis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_FunctionWrapperNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/control_flow/ssa.pyc\u001b[0m in \u001b[0;36mhandle_phis\u001b[0;34m(flow)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphi_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_phis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mprocess_incoming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/danielfrg/envs/copper/lib/python2.7/site-packages/numba/control_flow/ssa.pyc\u001b[0m in \u001b[0;36mprocess_incoming\u001b[0;34m(phi_node)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mincoming_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincoming_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mparent_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         phi.add_incoming(incoming_var.lvalue,\n",
        "\u001b[0;31mAssertionError\u001b[0m: Block(3)"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Cost function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function(weights, X, y, weights_meta, num_labels, reg_lambda):\n",
      "    m = X.shape[0]\n",
      "    Y = np.eye(num_labels)[y]\n",
      "    \n",
      "    h = forward(weights, weights_meta, X)\n",
      "    costPositive = -Y * np.log(h).T\n",
      "    costNegative = (1 - Y) * np.log(1 - h).T\n",
      "    cost = costPositive - costNegative\n",
      "    J = np.sum(cost) / m\n",
      "    \n",
      "    if reg_lambda != 0:\n",
      "        sums_qr = 0\n",
      "        for theta in unpack_weigths_gen(weights, weights_meta):\n",
      "            theta_filtered = theta[:, 1:]\n",
      "            sums_qr += np.sum(theta_filtered ** 2)  # sumsqr(theta_filtered)\n",
      "        reg = (reg_lambda / (2 * m)) * (sums_qr)\n",
      "        J = J + reg\n",
      "    return J"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function(thetas0, X, y, weights_meta, len(np.unique(y)), 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "7.5203245189536387"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Cost function derivative (backprop)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function_prime(weights, X, y, weights_meta, num_labels, reg_lambda):\n",
      "    m = X.shape[0]\n",
      "    Y = np.eye(num_labels)[y]\n",
      "    ones = np.array(1).reshape(1,)\n",
      "    \n",
      "    d_s = ()\n",
      "    Deltas = [np.zeros(w) for i, w in enumerate(weights_meta)]\n",
      "    for i, row in enumerate(X):\n",
      "        # Forward\n",
      "        a_prev = np.hstack((ones, row))  # Input layer\n",
      "        a_s = (a_prev, )  # a_s[0] == a1\n",
      "        for j, theta in enumerate(unpack_weigths_gen(weights, weights_meta)):\n",
      "            # Hidden Layers\n",
      "            z = np.dot(theta, a_prev.T)\n",
      "            a = sigmoid(z)\n",
      "            a_prev = np.hstack((ones, a.T))\n",
      "            a_s = a_s + (a_prev, )\n",
      "                \n",
      "        # Backprop\n",
      "        d_prev = a_s[-1][1:] - Y[i, :].T  # last d\n",
      "        d_s = (d_prev, )  # d_s[0] == d2 \n",
      "        for a_i, theta in zip(reversed(a_s[1:-1]), unpack_weigths_gen_inv(weights, weights_meta)):\n",
      "            d_new = np.dot(theta[:, 1:].T, d_prev) * (a_i[1:] * (1 - a_i[1:]))\n",
      "            d_s = (d_new, ) + d_s\n",
      "            d_prev = d_new\n",
      "        for d_i, a_i, i in zip(reversed(d_s), reversed(a_s[:-1]), range(len(Deltas) - 1, -1, -1)):\n",
      "            Deltas[i] = Deltas[i] + np.dot(d_i[np.newaxis].T, a_i[np.newaxis])\n",
      "    \n",
      "    thetas_gen = None\n",
      "    if reg_lambda != 0:\n",
      "        thetas_gen = unpack_weigths_gen(weights, weights_meta)\n",
      "    for i in range(len(Deltas)):\n",
      "        Deltas[i] = Deltas[i] / m\n",
      "        if reg_lambda != 0:\n",
      "            Deltas[i][:, 1:] = Deltas[i][:, 1:] + (reg_lambda / m) * thetas_gen.next()[:, 1:]\n",
      "    return pack_weigths(*tuple(Deltas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Others"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minibatch(X, y, batch_size=1):\n",
      "    m = X.shape[0]\n",
      "    batch_size = batch_size if batch_size >= 1 else int(math.floor(m * batch_size))\n",
      "    max_batchs = int(math.floor(m / batch_size))\n",
      "    \n",
      "    indices = np.random.choice(np.arange(m), m, replace=False)\n",
      "    X, y = X[indices], y[indices]\n",
      "    while True:\n",
      "        for i in range(max_batchs):\n",
      "            indices = np.arange(i * batch_size, (i + 1) * batch_size)\n",
      "            yield X[indices], y[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mb_gd(func, func_prime, thetas0, X, y, options=None, args=(), callback=None):\n",
      "    print 'MBGD'\n",
      "    batch_size = options['batch_size']\n",
      "    maxiter = options['maxiter']\n",
      "    learning_rate = options['learning_rate']\n",
      "    tol = options['tol']\n",
      "    disp = options['disp']\n",
      "    thetas = thetas0\n",
      "    diff = 1\n",
      "    prevJ = 1000\n",
      "    i = 0\n",
      "    for i, (_X, _y) in zip(range(1, maxiter + 1), minibatch(X, y, batch_size)):\n",
      "        thetas = thetas - learning_rate * func_prime(thetas, _X, _y, *args)\n",
      "        newJ = float(function(thetas, X, y, *args))\n",
      "        if not np.isnan(newJ) and newJ != float(\"inf\"):\n",
      "            diff = np.abs(newJ - prevJ)\n",
      "            \n",
      "            prevJ = newJ\n",
      "            if diff < tol or i >= maxiter:\n",
      "                break\n",
      "        if disp:\n",
      "            print i, newJ    \n",
      "        if callback is not None:\n",
      "            callback(i, thetas)\n",
      "        i += 1\n",
      "    return thetas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mb_rmsprop(func, func_prime, thetas0, X, y, options=None, args=(), callback=None):\n",
      "    print 'RMSPROP'\n",
      "    batch_size = options['batch_size']\n",
      "    maxiter = options['maxiter']\n",
      "    tol = options['tol']\n",
      "    disp = options['disp']\n",
      "    thetas = thetas0\n",
      "    diff = 1\n",
      "    prevJ = 1000\n",
      "    rms = 1\n",
      "    for i, (_X, _y) in zip(range(1, maxiter + 1), minibatch(X, y, batch_size)):\n",
      "        grad = func_prime(thetas, _X, _y, *args)\n",
      "        rms = 0.9 * rms + 0.1 * np.square(grad)\n",
      "        thetas = thetas - np.divide(grad, np.sqrt(rms))\n",
      "        newJ = float(function(thetas, X, y, *args))\n",
      "        if not np.isnan(newJ) and newJ != float(\"inf\"):\n",
      "            diff = np.abs(newJ - prevJ)\n",
      "            prevJ = newJ\n",
      "            if diff < tol or i >= maxiter:\n",
      "                break\n",
      "        if disp:\n",
      "            print i, newJ    \n",
      "        if callback is not None:\n",
      "            callback(i, thetas)\n",
      "    return thetas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mb_scipy(func, func_prime, thetas0, X, y, options=None, args=(), callback=None):\n",
      "    print 'scipy', options['mb_opti']\n",
      "    batch_size = options['batch_size']\n",
      "    maxiter = options['maxiter']\n",
      "    tol = options['tol']\n",
      "    disp = options['disp']\n",
      "    thetas = thetas0\n",
      "    diff = 1\n",
      "    prevJ = 1000\n",
      "    thetas = thetas0\n",
      "    for i, (_X, _y) in zip(range(1, maxiter + 1), minibatch(X, y, batch_size)):\n",
      "        ans = optimize.minimize(func, thetas, jac=func_prime, method=options['mb_opti'], \n",
      "                                args=(_X, _y) + args,\n",
      "                                options={'maxiter': options['mb_opti_maxiter']})\n",
      "        thetas = ans.x\n",
      "        newJ = float(function(thetas, X, y, *args))\n",
      "        if not np.isnan(newJ) and newJ != float(\"inf\"):\n",
      "            diff = np.abs(newJ - prevJ)\n",
      "            \n",
      "            prevJ = newJ\n",
      "            if diff < tol or i >= maxiter:\n",
      "                break\n",
      "        if disp:\n",
      "            print i, newJ\n",
      "        if callback is not None:\n",
      "            callback(i, thetas)\n",
      "    return thetas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mb_opti(func, func_prime, thetas0, X, y, options=None, args=(), callback=None):\n",
      "    if options['mb_opti'] == 'GD':\n",
      "        return mb_gd(function, function_prime, thetas0, X, y, options=options, args=args, callback=callback)\n",
      "    elif options['mb_opti'] == 'RMSPROP':\n",
      "        return mb_rmsprop(function, function_prime, thetas0, X, y, options=options, args=args, callback=callback)\n",
      "    else:\n",
      "        return mb_scipy(function, function_prime, thetas0, X, y, options=options, args=args, callback=callback)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NN(object):\n",
      "    \n",
      "    def __init__(self, hidden_layers, \n",
      "                 opti_method='MB', maxiter=100, tol=0.000001, \n",
      "                 mb_opti='CG', batch_size=0.1, learning_rate=0.3, \n",
      "                 mb_opti_maxiter=10,\n",
      "                 disp=False, opti_callback=None,\n",
      "                 act_func=sigmoid,\n",
      "                 epsilon_init=0.12, random_state=0, \n",
      "                 reg_lambda=0, coef0=None):\n",
      "        self.hidden_layers = hidden_layers\n",
      "        self.opti_method = opti_method\n",
      "        self.maxiter = maxiter\n",
      "        self.tol = tol\n",
      "        self.mb_opti = mb_opti\n",
      "        self.batch_size = batch_size\n",
      "        self.learning_rate = learning_rate\n",
      "        self.mb_opti_maxiter = mb_opti_maxiter\n",
      "        self.disp = disp\n",
      "        self.opti_callback = opti_callback\n",
      "        self.act_func = act_func\n",
      "        self.epsilon_init = epsilon_init\n",
      "        self.random_state = random_state\n",
      "        self.reg_lambda = reg_lambda\n",
      "        self.coef0 = coef0\n",
      "        self.meta_ = None\n",
      "        self.coef_ = None\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return forward(self.coef_, self.meta_, X, self.act_func).argmax(0)\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        layers = self.hidden_layers\n",
      "        layers.insert(0, X.shape[1])\n",
      "        layers.insert(len(layers), np.unique(y).shape[0])\n",
      "        weight_metadata = build_network(layers)\n",
      "        self.meta_ = weight_metadata\n",
      "        \n",
      "        np.random.seed(self.random_state)\n",
      "        thetas0 = self.coef0 if self.coef0 is not None else rand_init(weight_metadata, self.epsilon_init)\n",
      "        num_labels = len(np.unique(y))\n",
      "        \n",
      "        options = {}\n",
      "        options['maxiter'] = self.maxiter\n",
      "        options['disp'] = self.disp\n",
      "        _callback = None\n",
      "        \n",
      "        if self.opti_method == 'MB':\n",
      "            print 'fast'\n",
      "            if self.opti_callback is not None:\n",
      "                def _callback(i, thetas):\n",
      "                    self.coef_ = thetas\n",
      "                    self.opti_callback(self, i)\n",
      "            \n",
      "            options['mb_opti'] = self.mb_opti\n",
      "            options['batch_size'] = self.batch_size\n",
      "            options['learning_rate'] = self.learning_rate\n",
      "            options['tol'] = self.tol\n",
      "            options['mb_opti_maxiter'] = self.mb_opti_maxiter\n",
      "            ans = mb_opti(function, function_prime, thetas0, X, y, options=options, callback=_callback,\n",
      "                          args=(weight_metadata, num_labels, self.reg_lambda, self.act_func))\n",
      "        else:\n",
      "            print 'slow', self.opti_method\n",
      "            if self.opti_callback is not None:\n",
      "                def _callback(thetas):\n",
      "                    self.coef_ = thetas\n",
      "                    self.opti_callback(self, 0)\n",
      "            ans = optimize.minimize(function, thetas0, jac=function_prime, method=self.opti_method, \n",
      "                                    args=(X, y, weight_metadata, num_labels, self.reg_lambda, self.act_func),\n",
      "                                    options=options, callback=_callback)\n",
      "            ans = ans.x\n",
      "        self.coef_ = ans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = loadmat('ex3data1.mat')\n",
      "X, y = data['X'], data['y']\n",
      "y = y.reshape(X.shape[0], )\n",
      "y = y - 1  # Fix notation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cb(model, i):\n",
      "    print i, (nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='CG', maxiter=10, disp=False, mb_opti='CG', opti_callback=cb, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "slow CG\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1016\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4164\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.291\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.2536\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4086\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.525\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6458\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.6918\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.727\n",
        "1 loops, best of 1: 24.4 s per loop\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.72699999999999998"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "CG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='CG', maxiter=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "slow CG\n",
        "1 loops, best of 1: 267 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "0.98780000000000001"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "MB-CG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='CG', maxiter=100, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "scipy CG\n",
        "1 loops, best of 1: 9.18 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "0.88959999999999995"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='CG', maxiter=500, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "scipy CG\n",
        "1 loops, best of 1: 50.6 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "0.95940000000000003"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "MB-GD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='GD', maxiter=100, batch_size=100, learning_rate=0.3, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "MBGD\n",
        "1 loops, best of 1: 2.8 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "0.63959999999999995"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='GD', maxiter=500, batch_size=100, learning_rate=0.3, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "MBGD\n",
        "1 loops, best of 1: 13.4 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "0.88400000000000001"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='GD', maxiter=1000, batch_size=100, learning_rate=0.3, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "MBGD\n",
        "1 loops, best of 1: 25.9 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "0.91859999999999997"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='GD', maxiter=2000, batch_size=100, learning_rate=0.3, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "MBGD\n",
        "1 loops, best of 1: 51.4 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "0.94320000000000004"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RMSPROP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='RMSPROP', maxiter=100, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "RMSPROP\n",
        "1 loops, best of 1: 4.85 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "0.18360000000000001"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='RMSPROP', maxiter=500, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "RMSPROP\n",
        "1 loops, best of 1: 23.2 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "0.76800000000000002"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='RMSPROP', maxiter=1000, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "RMSPROP\n",
        "1 loops, best of 1: 47.8 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:7: RuntimeWarning: divide by zero encountered in log\n",
        "-c:7: RuntimeWarning: invalid value encountered in multiply\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "0.81259999999999999"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn = NN(hidden_layers=[25], opti_method='MB', mb_opti='RMSPROP', maxiter=2000, batch_size=100, disp=False, random_state=1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nn.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fast\n",
        "RMSPROP\n",
        "1 loops, best of 1: 98.3 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nn.predict(X) == y).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "0.90680000000000005"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}