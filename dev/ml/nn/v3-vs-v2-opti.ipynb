{
 "metadata": {
  "name": "v3-vs-v2-opti"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "from scipy import optimize\n",
      "from scipy.io import loadmat\n",
      "import sklearn.datasets as datasets\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "V2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "class NN_V2(object):\n",
      "    \n",
      "    def __init__(self, reg_lambda=0, epsilon_init=0.12, hidden_layer_size=25, opti_method='TNC', maxiter=500):\n",
      "        self.reg_lambda = reg_lambda\n",
      "        self.epsilon_init = epsilon_init\n",
      "        self.hidden_layer_size = hidden_layer_size\n",
      "        self.activation_func = self.sigmoid\n",
      "        self.activation_func_prime = self.sigmoid_prime\n",
      "        self.method = opti_method\n",
      "        self.maxiter = maxiter\n",
      "    \n",
      "    def sigmoid(self, z):\n",
      "        return 1 / (1 + np.exp(-z))\n",
      "    \n",
      "    def sigmoid_prime(self, z):\n",
      "        sig = self.sigmoid(z)\n",
      "        return sig * (1 - sig)\n",
      "    \n",
      "    def sumsqr(self, a):\n",
      "        return np.sum(a ** 2)\n",
      "    \n",
      "    def rand_init(self, l_in, l_out):\n",
      "        return np.random.rand(l_out, l_in + 1) * 2 * self.epsilon_init - self.epsilon_init\n",
      "    \n",
      "    def pack_thetas(self, t1, t2):\n",
      "        return np.concatenate((t1.reshape(-1), t2.reshape(-1)))\n",
      "    \n",
      "    def unpack_thetas(self, thetas, input_layer_size, hidden_layer_size, num_labels):\n",
      "        t1_start = 0\n",
      "        t1_end = hidden_layer_size * (input_layer_size + 1)\n",
      "        t1 = thetas[t1_start:t1_end].reshape((hidden_layer_size, input_layer_size + 1))\n",
      "        t2 = thetas[t1_end:].reshape((num_labels, hidden_layer_size + 1))\n",
      "        return t1, t2\n",
      "    \n",
      "    def _forward(self, X, t1, t2):\n",
      "        m = X.shape[0]\n",
      "        ones = None\n",
      "        if len(X.shape) == 1:\n",
      "            ones = np.array(1).reshape(1,)\n",
      "        else:\n",
      "            ones = np.ones(m).reshape(m,1)\n",
      "        \n",
      "        # Input layer\n",
      "        a1 = np.hstack((ones, X))\n",
      "        \n",
      "        # Hidden Layer\n",
      "        z2 = np.dot(t1, a1.T)\n",
      "        a2 = self.activation_func(z2)\n",
      "        a2 = np.hstack((ones, a2.T))\n",
      "        \n",
      "        # Output layer\n",
      "        z3 = np.dot(t2, a2.T)\n",
      "        a3 = self.activation_func(z3)\n",
      "        return a1, z2, a2, z3, a3\n",
      "    \n",
      "    def function(self, thetas, input_layer_size, hidden_layer_size, num_labels, X, y, reg_lambda):\n",
      "        t1, t2 = self.unpack_thetas(thetas, input_layer_size, hidden_layer_size, num_labels)\n",
      "        \n",
      "        m = X.shape[0]\n",
      "        Y = np.eye(num_labels)[y]\n",
      "        \n",
      "        _, _, _, _, h = self._forward(X, t1, t2)\n",
      "        costPositive = -Y * np.log(h).T\n",
      "        costNegative = (1 - Y) * np.log(1 - h).T\n",
      "        cost = costPositive - costNegative\n",
      "        J = np.sum(cost) / m\n",
      "        \n",
      "        if reg_lambda != 0:\n",
      "            t1f = t1[:, 1:]\n",
      "            t2f = t2[:, 1:]\n",
      "            reg = (self.reg_lambda / (2 * m)) * (self.sumsqr(t1f) + self.sumsqr(t2f))\n",
      "            J = J + reg\n",
      "        return J\n",
      "        \n",
      "    def function_prime(self, thetas, input_layer_size, hidden_layer_size, num_labels, X, y, reg_lambda):\n",
      "        t1, t2 = self.unpack_thetas(thetas, input_layer_size, hidden_layer_size, num_labels)\n",
      "        \n",
      "        m = X.shape[0]\n",
      "        t1f = t1[:, 1:]\n",
      "        t2f = t2[:, 1:]\n",
      "        Y = np.eye(num_labels)[y]\n",
      "        \n",
      "        Delta1, Delta2 = 0, 0\n",
      "        for i, row in enumerate(X):\n",
      "            a1, z2, a2, z3, a3 = self._forward(row, t1, t2)\n",
      "            \n",
      "            # Backprop\n",
      "            d3 = a3 - Y[i, :].T\n",
      "            d2 = np.dot(t2f.T, d3) * self.activation_func_prime(z2)\n",
      "            \n",
      "            Delta2 += np.dot(d3[np.newaxis].T, a2[np.newaxis])\n",
      "            Delta1 += np.dot(d2[np.newaxis].T, a1[np.newaxis])\n",
      "            \n",
      "        Theta1_grad = (1 / m) * Delta1\n",
      "        Theta2_grad = (1 / m) * Delta2\n",
      "        \n",
      "        if reg_lambda != 0:\n",
      "            Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (reg_lambda / m) * t1f\n",
      "            Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (reg_lambda / m) * t2f\n",
      "        \n",
      "        return self.pack_thetas(Theta1_grad, Theta2_grad)\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        #num_features = X.shape[0]\n",
      "        input_layer_size = X.shape[1]\n",
      "        num_labels = len(set(y))\n",
      "        \n",
      "        theta1_0 = self.rand_init(input_layer_size, self.hidden_layer_size)\n",
      "        theta2_0 = self.rand_init(self.hidden_layer_size, num_labels)\n",
      "        thetas0 = self.pack_thetas(theta1_0, theta2_0)\n",
      "        \n",
      "        options = {'maxiter': self.maxiter}\n",
      "        _res = optimize.minimize(self.function, thetas0, jac=self.function_prime, method=self.method, \n",
      "                                 args=(input_layer_size, self.hidden_layer_size, num_labels, X, y, 0), options=options)\n",
      "        \n",
      "        self.t1, self.t2 = self.unpack_thetas(_res.x, input_layer_size, self.hidden_layer_size, num_labels)\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return self.predict_proba(X).argmax(0)\n",
      "    \n",
      "    def predict_proba(self, X):\n",
      "        _, _, _, _, h = self._forward(X, self.t1, self.t2)\n",
      "        return h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "V3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_network(layers):\n",
      "    return [(layers[i+1], layers[i] + 1) for i in range(len(layers) - 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pack_weigths(*weights):\n",
      "    tuples = tuple([theta.reshape(-1) for theta in weights])\n",
      "    return np.concatenate(tuples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths_gen(weights, weights_meta):\n",
      "    start_pos = 0\n",
      "    for layer in weights_meta:\n",
      "        end_pos = start_pos + layer[0] * (layer[1])\n",
      "        theta = weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        yield theta\n",
      "        start_pos = end_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths_gen_inv(weights, weights_meta):\n",
      "    end_pos = len(weights)\n",
      "    for layer in reversed(weights_meta):\n",
      "        start_pos = end_pos - layer[0] * (layer[1])\n",
      "        theta = weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        yield theta\n",
      "        end_pos = start_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rand_init(weights_meta, epsilon_init):\n",
      "    s = 0\n",
      "    for t in weights_meta:\n",
      "        s += t[0] * t[1]\n",
      "    return np.random.rand(s, ) * 2 * epsilon_init - epsilon_init"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    return 1 / (1 + np.exp(-z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid_prime(z):\n",
      "    sig = sigmoid(z)\n",
      "    return sig * (1 - sig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def forward(weights, weights_meta, X, act_func):\n",
      "    m = X.shape[0]\n",
      "    ones = np.ones(m).reshape(m,1)\n",
      "            \n",
      "    a_prev = np.hstack((ones, X))  # Input layer\n",
      "    for theta in unpack_weigths_gen(weights, weights_meta):\n",
      "        # Hidden Layers\n",
      "        z = np.dot(theta, a_prev.T)\n",
      "        a = act_func(z)\n",
      "        a_prev = np.hstack((ones, a.T))\n",
      "    return a  # Output layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sumsqr(a):\n",
      "    return np.sum(a ** 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function(weights, weights_meta, X, y, reg_lambda, act_func, act_func_prime):\n",
      "    m = X.shape[0]\n",
      "    num_labels = len(np.unique(y))\n",
      "    Y = np.eye(num_labels)[y]\n",
      "    \n",
      "    h = forward(weights, weights_meta, X, act_func)\n",
      "    costPositive = -Y * np.log(h).T\n",
      "    costNegative = (1 - Y) * np.log(1 - h).T\n",
      "    cost = costPositive - costNegative\n",
      "    J = np.sum(cost) / m\n",
      "    \n",
      "    if reg_lambda != 0:\n",
      "        sums_qr = 0\n",
      "        for theta in unpack_weigths_gen(weights, weights_meta):\n",
      "            theta_filtered = theta[:, 1:]\n",
      "            sums_qr += sumsqr(theta_filtered)\n",
      "        reg = (reg_lambda / (2 * m)) * (sums_qr)\n",
      "        J = J + reg\n",
      "    return J"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def function_prime(weights, weights_meta, X, y, reg_lambda, act_func, act_func_prime):\n",
      "    m = X.shape[0]\n",
      "    num_labels = len(np.unique(y))\n",
      "    Y = np.eye(num_labels)[y]\n",
      "    \n",
      "    d_s = ()\n",
      "    Deltas = [np.zeros(w_info) for w_info in weights_meta]\n",
      "    for i, row in enumerate(X):\n",
      "        # Forward\n",
      "        ones = np.array(1).reshape(1,)\n",
      "        a_prev = np.hstack((ones, row))  # Input layer\n",
      "        a_s = (a_prev, ) ## a_s[0] == a1\n",
      "        z_s = ()  # z_s[0] == z2\n",
      "        for j, theta in enumerate(unpack_weigths_gen(weights, weights_meta)):\n",
      "            # Hidden Layers\n",
      "            z = np.dot(theta, a_prev.T)\n",
      "            z_s = z_s + (z, )\n",
      "            a = act_func(z)\n",
      "            a_prev = np.hstack((ones, a.T))\n",
      "            if j == len(weights_meta) - 1:\n",
      "                a_s = a_s + (a, )\n",
      "            else:\n",
      "                a_s = a_s + (a_prev, )\n",
      "                \n",
      "        # Backprop\n",
      "        # deltas:= error\n",
      "        d_prev = a_s[-1] - Y[i, :].T  # last d\n",
      "        d_s = (d_prev, )  # d_s[0] == d2\n",
      "        for z_i, theta in zip(reversed(z_s[:-1]), unpack_weigths_gen_inv(weights, weights_meta)):\n",
      "            d_new = np.dot(theta[:, 1:].T, d_prev) * act_func_prime(z_i)\n",
      "            d_s = (d_new, ) + d_s\n",
      "            d_prev = d_new\n",
      "        for d_i, a_i, i in zip(reversed(d_s), reversed(a_s[:-1]), range(len(Deltas) - 1, -1, -1)):\n",
      "            Deltas[i] = Deltas[i] + np.dot(d_i[np.newaxis].T, a_i[np.newaxis])\n",
      "    \n",
      "    thetas_gen = None\n",
      "    if reg_lambda != 0:\n",
      "        thetas_gen = unpack_weigths_gen(weights, weights_meta)\n",
      "    for i in range(len(Deltas)):\n",
      "        Deltas[i] = Deltas[i] / m\n",
      "        if reg_lambda != 0:\n",
      "            Deltas[i][:, 1:] = Deltas[i][:, 1:] + (reg_lambda / m) * thetas_gen.next()[:, 1:]\n",
      "    return pack_weigths(*tuple(Deltas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NN_V3(object):\n",
      "    \n",
      "    def __init__(self, hidden_layers=None, opti_method='TNC', maxiter=100, \n",
      "                 act_func=sigmoid, act_func_prime=sigmoid_prime,\n",
      "                 epsilon_init=0.12, reg_lambda=0,\n",
      "                 random_state=0):\n",
      "        assert hidden_layers is not None, \"Please specify hidden_layers\"\n",
      "        self.hidden_layers = hidden_layers\n",
      "        self.opti_method = opti_method\n",
      "        self.maxiter = maxiter\n",
      "        self.act_func = act_func\n",
      "        self.act_func_prime = act_func_prime\n",
      "        self.epsilon_init = epsilon_init\n",
      "        self.reg_lambda = 0\n",
      "        self.random_state = random_state\n",
      "        self.coef_ = None\n",
      "        \n",
      "    def fit(self, X, y):\n",
      "        layers = self.hidden_layers\n",
      "        layers.insert(0, X.shape[1])\n",
      "        layers.insert(len(layers), np.unique(y).shape[0])\n",
      "        weight_metadata = build_network(layers)\n",
      "        \n",
      "        np.random.seed(self.random_state)\n",
      "        thetas0 = rand_init(weight_metadata, self.epsilon_init)\n",
      "        options = {'maxiter': self.maxiter, 'disp':True}\n",
      "        ans = optimize.minimize(function, thetas0, jac=function_prime, method=self.opti_method, \n",
      "                                 args=(weight_metadata, X, y, self.reg_lambda, self.act_func, self.act_func_prime),\n",
      "                                 options=options)\n",
      "        self.coef_ = ans.x\n",
      "        self.meta_ = weight_metadata\n",
      "    \n",
      "    def predict(self, X):\n",
      "        return forward(self.coef_, self.meta_, X, self.act_func).argmax(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Benchmarks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = loadmat('ex3data1.mat')\n",
      "X, y = data['X'], data['y']\n",
      "y = y.reshape(X.shape[0], )\n",
      "y = y - 1  # Fix notation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nnv2 = NN_V2(maxiter=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nnv2.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 32.8 s per loop\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nnv2.predict(X_test) == y_test).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "0.88149999999999995"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nnv3 = NN_V3(hidden_layers=[25], maxiter=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit -n1 -r1 nnv3.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 1: 37.6 s per loop\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nnv3.predict(X_test) == y_test).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "0.90249999999999997"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}