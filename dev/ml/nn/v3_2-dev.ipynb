{
 "metadata": {
  "name": "v3_2-dev"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "from scipy import optimize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def softmax(x):\n",
      "    e = np.exp(x - np.max(x))  # prevent overflow\n",
      "    if e.ndim == 1:\n",
      "        return e / np.sum(e, axis=0)\n",
      "    else:  \n",
      "        return e / np.array([np.sum(e, axis=1)]).T  # ndim = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Layer(object):\n",
      "    def __init__(self, n_in=None, n_out=None, W=None, random_state=None, activation=None):\n",
      "        if random_state is None:\n",
      "            rnd = np.random.RandomState()\n",
      "        else:\n",
      "            rnd = random_state\n",
      "        \n",
      "        if W is None:\n",
      "            self.W = rnd.uniform(size=(n_in + 1, n_out))\n",
      "        else:\n",
      "            self.W = W\n",
      "        \n",
      "        self.activation = activation\n",
      "        \n",
      "    def output(self, input):\n",
      "        data = np.insert(input, 0, 1, axis=1)\n",
      "        linear_output = np.dot(data, self.W)\n",
      "        return self.activation(linear_output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticLayer(Layer):\n",
      "    def __init__(self, n_in=None, n_out=None, W=None, random_state=None):\n",
      "        Layer.__init__(self, n_in, n_out, W, random_state, activation=softmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loglay = LogisticLayer(4, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loglay.W.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(5, 3)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loglay.output(X).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(150, 3)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Hidden/Sigmoid Layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    return np.divide(1., (1 + np.exp(-z)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SigmoidLayer(Layer):\n",
      "    def __init__(self, n_in=None, n_out=None, W=None, random_state=None):\n",
      "        Layer.__init__(self, n_in, n_out, W, random_state, activation=sigmoid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siglay = SigmoidLayer(4, 7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siglay.W.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(5, 7)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "siglay.output(X).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(150, 7)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer_sizes = [25, 30]\n",
      "layer_sizes.insert(0, X.shape[1])\n",
      "layer_sizes.insert(len(layer_sizes), len(np.unique(y)))\n",
      "layer_sizes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[4, 25, 30, 3]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_network(layers):\n",
      "    return [(layers[i], layers[i + 1]) for i in range(len(layers) - 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_weights(layer_sizes, random_state):\n",
      "    weights_info = [(layer_sizes[i] + 1, layer_sizes[i + 1]) for i in range(len(layer_sizes) - 1)]\n",
      "    w_size = 0\n",
      "    for layer_info in weights_info:\n",
      "        w_size += layer_info[0] * layer_info[1]\n",
      "    return random_state.uniform(size=w_size), weights_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0, weights_info = create_weights(layer_sizes, np.random.RandomState(1234))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights_info,weights0.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "([(5, 25), (26, 30), (31, 3)], (998,))"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_layers(weights, weights_info):\n",
      "    layers = []\n",
      "    # Unpack the weights and assing them\n",
      "    start_pos = 0\n",
      "    for w_info in weights_info:\n",
      "        end_pos = start_pos + w_info[0] * (w_info[1])\n",
      "        weight = weights[start_pos:end_pos].reshape((w_info[0], w_info[1]))\n",
      "        layers.append(SigmoidLayer(W=weight))\n",
      "        start_pos = end_pos\n",
      "    return layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers = create_layers(weights0, weights_info)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[l.W.shape for l in layers]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[(5, 25), (26, 30), (31, 3)]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def forward(layers, X):  # aka predict_proba\n",
      "    output = layers[0].output(X)\n",
      "    for layer in layers[1:]:\n",
      "        output = layer.output(output)\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forward(layers, X).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(150, 3)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0[0] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers[0].W[:2, :5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "array([[ 1.        ,  0.62210877,  0.43772774,  0.78535858,  0.77997581],\n",
        "       [ 0.65137814,  0.39720258,  0.78873014,  0.31683612,  0.56809865]])"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cost function and gradient"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0, weights_info = create_weights(layer_sizes, np.random.RandomState(1234))\n",
      "layers = create_layers(weights0, weights_info)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0.shape, weights0[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "((998,),\n",
        " array([ 0.19151945,  0.62210877,  0.43772774,  0.78535858,  0.77997581,\n",
        "        0.27259261,  0.27646426,  0.80187218,  0.95813935,  0.87593263]))"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers[0].W[:2, :5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([[ 0.19151945,  0.62210877,  0.43772774,  0.78535858,  0.77997581],\n",
        "       [ 0.65137814,  0.39720258,  0.78873014,  0.31683612,  0.56809865]])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths(weights, weights_meta):\n",
      "    start_pos = 0\n",
      "    for layer in weights_meta:\n",
      "        end_pos = start_pos + layer[0] * (layer[1])\n",
      "        yield weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        start_pos = end_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cost(weights, X, y, weights_meta, num_labels):\n",
      "    # Forward\n",
      "    act_prev = np.insert(X, 0, 1, axis=1)\n",
      "    for weight in unpack_weigths(weights, weights_meta):\n",
      "        z = np.dot(act_prev, weight)\n",
      "        activation = sigmoid(z)\n",
      "        act_prev = np.insert(activation, 0, 1, axis=1)\n",
      "    \n",
      "    Y = np.eye(num_labels)[y]\n",
      "    h = activation\n",
      "    costPositive = -Y * np.log(h)\n",
      "    costNegative = (1 - Y) * np.log(1 - h)\n",
      "    J = np.sum(costPositive - costNegative) / X.shape[0]\n",
      "    \n",
      "    return J"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost(weights0, X, y, weights_info, len(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "31.397997599425246"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unpack_weigths_inv(weights, weights_meta):\n",
      "    end_pos = len(weights)\n",
      "    for layer in reversed(weights_meta):\n",
      "        start_pos = end_pos - layer[0] * (layer[1])\n",
      "        yield weights[start_pos:end_pos].reshape((layer[0], layer[1]))\n",
      "        end_pos = start_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cost_prime(weights, X, y, weights_meta, num_labels):\n",
      "    Y = np.eye(num_labels)[y]\n",
      "    Deltas = [np.zeros(shape) for shape in weights_meta]\n",
      "    \n",
      "    data = np.insert(X, 0, 1, axis=1)\n",
      "    for i, row in enumerate(data):\n",
      "        # Forward\n",
      "        #row = np.array([row])\n",
      "        act_prev = row\n",
      "        activations = (act_prev, )\n",
      "        for weight in unpack_weigths(weights, weights_meta):\n",
      "            z = np.dot(act_prev, weight)\n",
      "            activation = sigmoid(z)\n",
      "            act_prev = np.append(1, activation)\n",
      "            activations = activations + (act_prev, )\n",
      "        \n",
      "        # Backprop\n",
      "        prev_delta = activations[-1][1:] - Y[i, :].T  # last delta\n",
      "        deltas = (prev_delta, )  # deltas[0] == delta2\n",
      "        for act, weight in zip(reversed(activations[1:-1]), unpack_weigths_inv(weights, weights_meta)):\n",
      "            delta = np.dot(weight, prev_delta)[1:] * (act[1:] * (1 - act[1:])).T\n",
      "            deltas = (delta, ) + deltas\n",
      "            prev_delta = delta\n",
      "\n",
      "        # Accumulate errors\n",
      "        for delta, act, i in zip(deltas, activations[:-1], range(len(Deltas))):\n",
      "            Deltas[i] = Deltas[i] + np.dot(delta[np.newaxis].T, act[np.newaxis]).T\n",
      "    for i in range(len(Deltas)):\n",
      "        Deltas[i] = Deltas[i] / X.shape[0]\n",
      "    return np.concatenate(tuple([D.reshape(-1) for D in Deltas]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost_prime(weights0, X, y, weights_info, len(np.unique(y)))[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([  1.57880739e-07,   1.09050540e-07,   1.59794342e-08,\n",
        "         2.27139143e-06,   4.51481472e-08,   5.70543666e-09,\n",
        "         7.71786320e-08,   1.75347728e-09,   8.93488019e-08,\n",
        "         5.89878368e-09,   1.71267237e-07,   1.59582181e-07,\n",
        "         6.52428875e-09,   1.73089602e-07,   1.86700579e-08,\n",
        "         5.82387482e-06,   4.18367021e-07,   3.50756385e-07,\n",
        "         4.60059687e-08,   1.54522762e-07])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optimization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minibatches(X, y=None, batch_size=50):\n",
      "    m = X.shape[0]\n",
      "    batch_size = batch_size if batch_size >= 1 else int(math.floor(m * batch_size))\n",
      "    max_batchs = int(math.floor(m / batch_size))\n",
      "    \n",
      "    while True:\n",
      "        indices = np.random.choice(np.arange(m), m, replace=False)\n",
      "        for i in range(max_batchs):\n",
      "            indices = np.arange(i * batch_size, (i + 1) * batch_size)\n",
      "            if y is None:\n",
      "                yield X[indices]\n",
      "            else:\n",
      "                yield X[indices], y[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb = minibatches(X, batch_size=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mb.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "       [ 4.9,  3. ,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.3,  0.2],\n",
        "       [ 4.6,  3.1,  1.5,  0.2],\n",
        "       [ 5. ,  3.6,  1.4,  0.2]])"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MinibatchOpti(object):\n",
      "    \n",
      "    @staticmethod\n",
      "    def minibatches(X, y=None, batch_size=50):\n",
      "        m = X.shape[0]\n",
      "        batch_size = batch_size if batch_size >= 1 else int(math.floor(m * batch_size))\n",
      "        max_batchs = int(math.floor(m / batch_size))\n",
      "        \n",
      "        while True:\n",
      "            indices = np.random.choice(np.arange(m), m, replace=False)\n",
      "            for i in range(max_batchs):\n",
      "                indices = np.arange(i * batch_size, (i + 1) * batch_size)\n",
      "                if y is None:\n",
      "                    yield X[indices]\n",
      "                else:\n",
      "                    yield X[indices], y[indices]\n",
      "    @staticmethod\n",
      "    def GD(fun, weights, jac, X, y, options, args=()):\n",
      "        weights2 = weights - options['learning_rate'] * jac(weights, X, y, *args)\n",
      "        options['learning_rate'] = options['learning_rate'] * options['learning_rate_decay']\n",
      "        return weights2\n",
      "    \n",
      "    @staticmethod\n",
      "    def minimize(fun, weights, jac, method=None, batch_size=50, tol=1e-6, maxiter=100, args=None, disp=False, options=None, callback=None):\n",
      "        if method == 'GD':\n",
      "            update = MinibatchOpti.GD\n",
      "        else:\n",
      "            raise 'Optimization method not found'\n",
      "\n",
      "        i = 1\n",
      "        prevJ = 1000\n",
      "        #weights = weights0\n",
      "        for _X, _y in MinibatchOpti.minibatches(X, y, batch_size):\n",
      "            weights[:] = update(fun, weights, jac, _X, _y, options, args=args)\n",
      "            #print weights[:10]\n",
      "            newJ = float(fun(weights, X, y, *args))\n",
      "            diff = newJ - prevJ\n",
      "            if np.abs(diff) < tol or i >= maxiter:\n",
      "                break\n",
      "            if disp:\n",
      "                print i, newJ    \n",
      "            if callback is not None:\n",
      "                callback(i, weights)\n",
      "            prevJ = newJ\n",
      "            i = i + 1\n",
      "        #return weights0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0, weights_info = create_weights(layer_sizes, np.random.RandomState(1234))\n",
      "layers = create_layers(weights0, weights_info)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights0[:10] # Original"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "array([ 0.19151945,  0.62210877,  0.43772774,  0.78535858,  0.77997581,\n",
        "        0.27259261,  0.27646426,  0.80187218,  0.95813935,  0.87593263])"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers[0].W[0][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "array([ 0.19151931,  0.62210864,  0.43772772,  0.78535578,  0.77997575,\n",
        "        0.2725926 ,  0.27646418,  0.80187218,  0.95813927,  0.87593263])"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "options = {}\n",
      "options['learning_rate'] = 0.3\n",
      "options['learning_rate_decay'] = 0.8\n",
      "MinibatchOpti.minimize(cost, weights0, cost_prime, method='GD', batch_size=50, disp=True, maxiter=100, args=(weights_info, len(np.unique(y))), options=options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 6.24495555093\n",
        "2 4.4671255049\n",
        "3 3.21646955792\n",
        "4 3.16359758995\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.56248185537\n",
        "6 2.21337212557\n",
        "7 2.12576463776\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.03288101828\n",
        "9 1.97554452138\n",
        "10 1.95413756507\n",
        "11 1.93725496551\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.92509085039\n",
        "13 1.92058212587\n",
        "14 1.91689599158\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91381573696\n",
        "16 1.91288820563\n",
        "17 1.91199850359\n",
        "18 1.91108878005\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91092883876\n",
        "20 1.91070000601\n",
        "21 1.91039019101\n",
        "22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91038467434\n",
        "23 1.91032265514\n",
        "24 1.91020253039\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91021891613\n",
        "26 1.91020106936\n",
        "27 1.91014934956\n",
        "28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.91016266784\n",
        "29 1.91015710415\n",
        "30 1.91013314782\n",
        "31 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.91014124458\n",
        "32 1.91013932332\n",
        "33 1.91012771398\n",
        "34 1.91013219259\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layers[0].W[0][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "array([ 0.19151931,  0.62210864,  0.43772772,  0.78535578,  0.77997575,\n",
        "        0.2725926 ,  0.27646418,  0.80187218,  0.95813927,  0.87593263])"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict(layers, X):\n",
      "    return forward(layers, X).argmax(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict(layers, X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}